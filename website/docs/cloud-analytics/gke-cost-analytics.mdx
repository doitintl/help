---
sidebar_position: 14
description: Unlock Google Kubernetes Engine cost data and make it available in Cloud Analytics
---

# GKE Cost Analytics

GKE Cost Analytics in the CMP helps you demystify your Google Kubernetes Engine (GKE) spend.

## Overview

With real-time visibility into GKE spend, you'll be able to:

- Accurately track the total cost of ownership (TCO) of Kubernetes-based workloads across teams or product lines.

- Plan better with realistic Kubernetes-based [budgets](manage-budgets.mdx).

- [Forecast](reports/forecasting.mdx) and [identify trends](reports/trend-analysis.mdx) across Kubernetes primitives in one click.

:::info

GKE Cost Analytics is not applicable to **Autopilot clusters**, which do not support usage metering (see [Google Cloud Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview#unsupported_cluster_features)).

:::

## Set up GKE Cost Analytics

:::note

For the GKE Cost Analytics feature to function properly, you need to complete all the steps below.

:::

### Step 1 &mdash; Enable GKE Cost Analytics

To enable GKE Cost Analytics, you need to [connect your Google Cloud Organization](../google-cloud/connect-google-cloud-service-account.mdx) and grant the required permissions to the CMP.

1. To check the status of your service account, log in to the CMP, select the _Settings_ icon (a gear) from the top menu bar, and then select **Google Cloud**.

2. Select the **GKE Cost Analytics** checkbox to enable the feature.

   <picture
     img={require('../../assets/png/cmp-gke-cost-analytics-enable.png')}
     alt="A screenshot highlighting the GKE Cost Analytics feature"
     frame="drop-shadow"
   />

3. Select **Update role**.

   A slide-out will appear containing the `gcloud` commands you need to run to update your service account's role.

### Step 2 &mdash; Enable the Kubernetes Engine API

1. In the Google Cloud console, on the project selector page, select the project where you created the service account.

2. Enable the Google Kubernetes Engine APIs.

See [Google Cloud Docs](https://cloud.google.com/kubernetes-engine/docs/deploy-app-cluster#before-you-begin) for details.

### Step 3 &mdash; Enable GKE usage metering

In this step, you enable GKE usage metering for your GKE clusters:

1. Create a BigQuery dataset. You can use [Google Cloud console](https://cloud.google.com/bigquery/docs/datasets#console) or [Terraform](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset).

2. Configure your clusters to export their resource usage to the newly created BigQuery dataset by enabling GKE usage metering on new or existing clusters.

   You can use the following methods:

   - Google Cloud console: See [Google Cloud Docs](https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-usage-metering#console).

   - gcloud command: Run the following command to create a cluster with GKE usage metering enabled (see [Google Cloud Docs](https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-usage-metering#gcloud) for more information).

     ```bash
     gcloud container clusters create $CLUSTER_NAME \
     --resource-usage-bigquery-dataset $RESOURCE_USAGE_DATASET
     ```

   - [Terraform Kubernetes Engine Module](https://registry.terraform.io/modules/terraform-google-modules/kubernetes-engine/google/latest): Set `enable_resource_consumption_export = true` to enable resource consumption metering on the cluster. When enabled, a table will be created in the resource export BigQuery dataset to store resource consumption data.

:::note

- It's possible to have multiple clusters in one project writing to the same BigQuery dataset.

- Clusters can export usage data only to the BigQuery datasets in the same project.

:::

### Step 4 &mdash; Grant the BigQuery Data Viewer role

You can grant the _BigQuery Data Viewer_ role to the service account for each GKE usage dataset by using the Google Cloud console or the Google Cloud Shell.

#### Use the Google Cloud console

1. Navigate to the BigQuery console and locate the dataset created in [Step 3](#step-3--enable-gke-usage-metering).

2. Select **Share Dataset**.

   <picture
     img={require('../../assets/png/gcp-share-dataset-button.png')}
     alt="A screenshot showing you the location of the Share Dataset button"
   />

3. In the **Add members** field, enter the email address of the service account configured in [Step 1](#step-1--enable-gke-cost-analytics).

4. Grant the service account the _BigQuery Data Viewer_ role, select **Add**, and then select **Done** to apply the changes.

   <picture
     img={require('../../assets/png/gcp-grant-bigquery-data-view-role.png')}
     alt="A screenshot showing how to grant the BigQuery Data Viewer role"
     frame="drop-shadow"
   />

#### Use the Google Cloud Shell

Copy the command code snippets below and run them in sequence in the Google Cloud Shell.

```bash
gcloud config set project $customer_billing_project_id

bq show --format=prettyjson $DATASET_ID |
  jq '.access = .access + [{"role": "READER", "userByEmail": "$customer_service_account' \
  >permissions.json

bq update --source permissions.json $DATASET_ID
```

#### Verify the access

Check that the access to the _BigQuery Data Viewer_ role has been granted.

Datasets with missing permissions are listed in the **Features** widget. They are not available in the GKE Cost Analytics feature.

<picture
  img={require('../../assets/png/cmp-gke-dataset-permission.png')}
  alt="A screenshot showing datasets with missing permissions"
  frame="drop-shadow"
/>

## Analyze GKE cost

Once you've set up GKE Cost Analytics, additional Google Kubernetes Engine dimensions and GKE Labels will be available in [Cloud Analytics Reports](reports/index.mdx).

You can drag a GKE chip or a GKE label chip into the **Group by** or **Dimensions** section to start understanding the real costs of running Kubernetes-based workloads on GKE. See [Dimensions, Group by, and Filters](reports/report-dimensions-groupings-and-filters.mdx) for more information.

## Limitations

- GKE reports only show data from the day when all the steps were completed. If you need to load historical data (i.e. _backfill_), please contact DoiT support team to file a backfill request.

- If you never enabled _GKE usage metering_ in the Google Cloud Console before setting up GKE Cost Analytics, we will not be able to show historical data in GKE reports.

- After you complete all the steps, it usually takes around four hours for you to be able to use GKE reports in Cloud Analytics.

- GKE reports are not compatible with some of the dimensions. For example, you will not be able to create a report that is based on the _GKE Cluster_ field and the _Zone_ field. You also cannot combine Google Cloud Labels and GKE Labels in the same report.
